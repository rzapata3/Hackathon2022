{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dc3febc-4968-44dc-abd3-c92ce75f9cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"/home/alexanderalbizu\")\n",
    "sys.path.append(\"/home/alexanderalbizu/.local/bin\")\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"CNN_III.ipynb\"\n",
    "# !pip install wandb\n",
    "# !pip install 'monai[all]'\n",
    "# !pip -q install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5be71323-075d-4572-9b67-5e255af752de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.8.1+337.g26fc4ba8.dirty\n",
      "Numpy version: 1.20.1\n",
      "Pytorch version: 1.9.0+cu111\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "MONAI rev id: 26fc4ba80c26d09c467fc45a7ca2c710f5dca087\n",
      "MONAI __file__: /home/alexanderalbizu/MONAI/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.8\n",
      "Nibabel version: 3.2.1\n",
      "scikit-image version: 0.19.1\n",
      "Pillow version: 9.1.1\n",
      "Tensorboard version: 1.15.0+nv\n",
      "gdown version: 4.4.0\n",
      "TorchVision version: 0.10.0+cu111\n",
      "tqdm version: 4.53.0\n",
      "lmdb version: 1.2.1\n",
      "psutil version: 5.8.0\n",
      "pandas version: 1.1.4\n",
      "einops version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: 1.26.1\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maalbizu\u001b[0m (\u001b[33mwoodslab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2020 MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import glob, math, os, shutil, tempfile, time, monai, torch, random\n",
    "\n",
    "# %load_ext line_profiler\n",
    "import wandb as wb\n",
    "from enum import Enum\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.under_sampling import AllKNN\n",
    "from monai.networks.utils import eval_mode\n",
    "from torch.nn import functional as nn\n",
    "from monai.config import print_config\n",
    "from monai.data import (\n",
    "    CacheDataset,\n",
    "    DataLoader,\n",
    "    ThreadDataLoader,\n",
    "    ImageDataset,\n",
    "    Dataset,\n",
    "    decollate_batch,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.losses import DiceLoss, DiceCELoss\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.layers import Act, Norm\n",
    "from monai.transforms import (\n",
    "    AddChannel,\n",
    "    Compose,\n",
    "    RandGaussianNoise,\n",
    "    Resize,\n",
    "    RemoveRepeatedChannel,\n",
    "    Orientation,\n",
    "    RandRotate90,\n",
    "    RandBiasField,\n",
    "    ScaleIntensity,\n",
    "    ToDevice,\n",
    "    AsChannelFirst,\n",
    "    EnsureType,\n",
    "    LoadImage,\n",
    "    Orientation,\n",
    "    RandFlip,\n",
    "    RandShiftIntensity,\n",
    "    Spacing,\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "pin_memory = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "print_config()\n",
    "wb.login(); # 7e5f63e5846f29b034d98806712ab047df76834d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6bbeee4-4365-4bc7-a277-5b09c4b5f5d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set data directory\n",
    "rootDir = '/blue/camctrp/working/gullettj/ACT/derivatives/SVM/'\n",
    "anatDir = '/blue/camctrp/working/gullettj/ACT/organized_data/';\n",
    "funcDir = '/blue/camctrp/working/gullettj/ACT/derivatives/SVM/func/';\n",
    "sdata = pd.read_csv(os.path.join(rootDir,'subjects_pre-mci_classification.csv')).to_numpy();\n",
    "\n",
    "# Training Settings\n",
    "batch_size=32\n",
    "max_epochs=10\n",
    "val_interval = 1\n",
    "\n",
    "# Parameter Settings\n",
    "im_size = (64,64,64)\n",
    "grad_clip = 2\n",
    "step_size = 1\n",
    "gamma = 7e-1\n",
    "lr = 1e-5\n",
    "gr = 16\n",
    "wd = 1e-6\n",
    "seed = 42\n",
    "sp = os.path.join(rootDir,\"T1\"); # Save Path\n",
    "\n",
    "# Subjects to Remove\n",
    "samples_to_exclude = np.array([103744,106986,300142,101644,105903,106078,106817,101395,105554,204085]) # 20ch headcoils\n",
    "exclude = np.equal(np.isin(sdata[:,0],samples_to_exclude),0);\n",
    "\n",
    "num_cores = int(os.environ[\"SLURM_CPUS_PER_TASK\"]);\n",
    "\n",
    "# Two binary labels for Healthy vs pre-MCI\n",
    "subIdx = np.arange(sdata[exclude,0].shape[0]);\n",
    "lab = np.array([sdata[:,1]]);\n",
    "lab = lab[:,exclude]; \n",
    "\n",
    "class Diagnosis(Enum):\n",
    "    normal = 0\n",
    "    preMCI = 1\n",
    "    \n",
    "# Structural MRI\n",
    "images = np.array([os.path.join(anatDir,''.join(['sub-',str(sdata[s,0])]),'ses-01','anat',''.join(['csub-',str(sdata[s,0]),'_ses-01_T1w.nii'])) for s in range(sdata.shape[0])]);\n",
    "# images = np.array([os.path.join(rootDir,'anat',''.join(['wc0csub-',str(sdata[s,0]),'_ses-01_T1w.nii'])) for s in range(sdata.shape[0])]);\n",
    "images = images[exclude]; \n",
    "\n",
    "# Functional MRI\n",
    "fc = np.array([os.path.join(rootDir,'func',''.join(['sub-',str(sdata[s,0]),'_ROIconnectivity.png'])) for s in range(sdata.shape[0])]);\n",
    "fc = fc[exclude];\n",
    "\n",
    "# Plot Labels\n",
    "plt.rcParams['figure.figsize'] = [20, 20]; plt.imshow(lab); \n",
    "plt.axis('off'); plt.title('Class Labels');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e66a511e-d06d-4e7b-ab07-eea892aad617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train case split:  53 : 221\n",
      "valid case split:  6 : 25\n",
      "test case split:  7 : 27 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed)    \n",
    "\n",
    "# Oversample Minority Class\n",
    "oversample = RandomOverSampler(sampling_strategy='minority',random_state=seed);\n",
    "# X, y = oversample.fit_resample(np.asarray([subIdx,subIdx]).T,lab[0,:]);\n",
    "\n",
    "# Oversampling Minority Class with SVM\n",
    "sm = SVMSMOTE(sampling_strategy='minority', random_state=seed)\n",
    "# X, y = sm.fit_resample(np.asarray([subIdx,subIdx]).T,lab[0,:]);\n",
    "\n",
    "# Undersample Majority Class\n",
    "# undersample = RandomUnderSampler(sampling_strategy='majority',random_state=seed);\n",
    "# X, y = undersample.fit_resample(np.asarray([subIdx,subIdx]).T,lab[0,:]);\n",
    "\n",
    "# Undersample Majority Class by KNN\n",
    "# X, y = AllKNN().fit_resample(np.asarray([subIdx,subIdx]).T,lab[0,:]);\n",
    "\n",
    "X, y = np.asarray([subIdx, subIdx]).T, lab[0,:]\n",
    "\n",
    "nontest_list, test_list, nontest_label, test_label = train_test_split(X[:,0], y,\n",
    "                                          test_size=0.10,\n",
    "                                          stratify=y,\n",
    "                                          random_state=seed)\n",
    "train_list, valid_list, train_label, valid_label = train_test_split(nontest_list, nontest_label,\n",
    "                                          test_size=0.10,\n",
    "                                          stratify=nontest_label,\n",
    "                                          random_state=seed)\n",
    "\n",
    "# Oversampling with SVM\n",
    "# train_list, train_label = sm.fit_resample(np.asarray([train_list,train_list]).T,train_label); train_list = train_list[:,0];\n",
    "# valid_list, valid_label = sm.fit_resample(np.asarray([valid_list,valid_list]).T,valid_label); valid_list = valid_list[:,0];\n",
    "\n",
    "# Oversampling \n",
    "# train_list, train_label = oversample.fit_resample(np.asarray([train_list,train_list]).T,train_label); train_list = train_list[:,0];\n",
    "# valid_list, valid_label = oversample.fit_resample(np.asarray([valid_list,valid_list]).T,valid_label); valid_list = valid_list[:,0];\n",
    "\n",
    "train_label_freq = {1: sum(train_label) / len(train_label)}\n",
    "train_label_freq[0] = 1 - train_label_freq[1]\n",
    "valid_label_freq = {1: sum(valid_label) / len(valid_label)}\n",
    "valid_label_freq[0] = 1 - valid_label_freq[1]\n",
    "test_label_freq = {1: sum(test_label) / len(test_label)}\n",
    "test_label_freq[0] = 1 - test_label_freq[1]\n",
    "\n",
    "print('train case split: ',sum(train_label),':',len(train_label)-sum(train_label))\n",
    "print('valid case split: ',sum(valid_label),':',len(valid_label)-sum(valid_label))\n",
    "print('test case split: ',sum(test_label),':',len(test_label)-sum(test_label),'\\n')\n",
    "del nontest_list, nontest_label; # Save RAM\n",
    "\n",
    "# Plot Responder Mean\n",
    "# plt.rcParams['figure.figsize'] = [5,5];\n",
    "# np.disp(''.join(['sub-',str(sdata[0,0]),' (1/',str(sdata.shape[0]),') T1 Data']));\n",
    "# nii = nib.load(images[0]); print(nii.shape) # Load Each Electrode\n",
    "# plt.imshow(nii.get_fdata()[:, :, 150].T, cmap=\"gray\", origin=\"lower\"); plt.axis('off'); # Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f77f5c69-f8a5-4dac-93b2-a23ed2ed4533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represent labels in one-hot format for binary classifier training,\n",
    "# BCEWithLogitsLoss requires target to have same shape as input\n",
    "labels = torch.nn.functional.one_hot(torch.as_tensor(lab.T)).long();\n",
    "train_lab = torch.nn.functional.one_hot(torch.as_tensor(train_label.T)).long(); \n",
    "valid_lab = torch.nn.functional.one_hot(torch.as_tensor(valid_label.T)).long();\n",
    "test_lab = torch.nn.functional.one_hot(torch.as_tensor(test_label.T)).long();\n",
    "\n",
    "# Define transforms\n",
    "train_transforms = Compose([\n",
    "            AddChannel(),\n",
    "            RandFlip(\n",
    "                spatial_axis=[0],                   \n",
    "                prob=0.10,\n",
    "            ),\n",
    "            RandFlip(\n",
    "                spatial_axis=[1],\n",
    "                prob=0.10,\n",
    "            ),\n",
    "            RandFlip(\n",
    "                spatial_axis=[2],\n",
    "                prob=0.10,\n",
    "            ),\n",
    "            RandRotate90(\n",
    "                prob=0.10,\n",
    "                max_k=3,\n",
    "            ),\n",
    "            RandShiftIntensity(\n",
    "                offsets=0.10,\n",
    "                prob=0.50,\n",
    "            ),\n",
    "            Spacing(\n",
    "                pixdim=(1.0, 1.0, 1.0), # HARDCODED\n",
    "                mode=\"bilinear\",\n",
    "                image_only=True,\n",
    "            ),    \n",
    "            Orientation(\n",
    "                axcodes=\"RAS\", \n",
    "                image_only=True,\n",
    "            ),        \n",
    "            ScaleIntensity(\n",
    "                minv=0.0,\n",
    "                maxv=1.0,\n",
    "            ),\n",
    "            Resize(im_size),\n",
    "            EnsureType(data_type='tensor'),\n",
    "        ]);\n",
    "\n",
    "val_transforms = Compose([\n",
    "            AddChannel(),\n",
    "            Spacing(\n",
    "                pixdim=(1.0, 1.0, 1.0), \n",
    "                mode=\"bilinear\", \n",
    "                image_only=True,\n",
    "            ),\n",
    "            Orientation(\n",
    "                axcodes=\"RAS\", \n",
    "                image_only=True,\n",
    "            ),\n",
    "            ScaleIntensity(\n",
    "                minv=0.0, \n",
    "                maxv=1.0, \n",
    "            ),\n",
    "            Resize(im_size),\n",
    "            EnsureType(data_type='tensor'),\n",
    "        ]);\n",
    "\n",
    "# Define nifti dataset, data loader\n",
    "check_ds = ImageDataset(image_files=images, labels=labels, transform=train_transforms);\n",
    "check_loader = DataLoader(check_ds, batch_size=1, num_workers=num_cores, pin_memory=pin_memory);\n",
    "\n",
    "# im, label = monai.utils.misc.first(check_loader); print(im.shape, label, label.shape)\n",
    "# plt.imshow(im[0,0,:,:,60].T, cmap=\"gray\", origin=\"lower\"); plt.axis('off'); del check_ds, check_loader, im, label;\n",
    "\n",
    "# create a training data loader\n",
    "train_ds = ImageDataset(image_files=images[train_list], labels=train_lab, transform=train_transforms);\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_cores, pin_memory=pin_memory);\n",
    "\n",
    "# create a validation data loader\n",
    "val_ds = ImageDataset(image_files=images[valid_list], labels=valid_lab, transform=val_transforms);\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, num_workers=num_cores, pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5362ef16-4488-4e09-be01-46aeda83bfc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/alexanderalbizu/MONAI/wandb/run-20221026_202716-37ev097o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/woodslab/HACKATHON/runs/37ev097o\" target=\"_blank\">drawn-dream-14</a></strong> to <a href=\"https://wandb.ai/woodslab/HACKATHON\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def save_model(n_epoch, save_path, run_id):\n",
    "        lastmodel = f\"{save_path}-{run_id}.pth\"\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"best_valid_score\": best_valid_score,\n",
    "                \"n_epoch\": n_epoch,\n",
    "            },\n",
    "            lastmodel,\n",
    "        )\n",
    "\n",
    "# Loss Function\n",
    "loss_fx = nn.binary_cross_entropy_with_logits # BCE\n",
    "\n",
    "wb.init(project=\"HACKATHON\",\n",
    "           config={\n",
    "               \"batch_size\": batch_size,\n",
    "               \"n_epoch\": max_epochs,\n",
    "               \"image_size\": im_size,\n",
    "               \"gradient_clip\": grad_clip,\n",
    "               \"learning_rate\": lr,\n",
    "               \"growth_rate\": gr,\n",
    "               \"step_size\": step_size,\n",
    "               \"network\": \"DenseNet264\",\n",
    "               \"gamma\": gamma,\n",
    "               \"weight_decay\": wd,\n",
    "               \"sampling\": \"\",\n",
    "               \"dataset\": \"ACT\",\n",
    "           }, entity=\"woodslab\")\n",
    "run_id = wb.run.name;\n",
    "modelfiles = [None,None] # Pre-allocate for Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a46ab7-9496-453f-8bd3-81af17fe5d81",
   "metadata": {},
   "source": [
    "# Train CNN for Structural Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fa623cd-d78a-4332-85fb-d50e853a876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start a typical PyTorch training\n",
    "epoch_loss_values = [] # Pre-Allocate\n",
    "epoch_acc_values = [] # Pre-Allocate\n",
    "sp = os.path.join(rootDir,\"T1\"); # Save Path\n",
    "\n",
    "# Create DenseNet264, CrossEntropyLoss and Adam optimizer\n",
    "model = monai.networks.nets.DenseNet264(spatial_dims=3, in_channels=1, out_channels=2, growth_rate=gr).to(device) # DenseNet\n",
    "# model.summary()\n",
    "wb.watch(model, log='all')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd) # Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "345ffe80-f75f-49d2-a515-5d880513b81e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "tensor([1, 0])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d46389537f2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mepoch_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtrain_label_freq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;31m# Scale loss by the freq of NOT this class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: tensor([1, 0])"
     ]
    }
   ],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()\n",
    "best_valid_score = 99999; # Initialize Loss\n",
    "lastmodel = None;\n",
    "for epoch in range(max_epochs):\n",
    "    epoch_loss = 0; \n",
    "    epoch_accuracy = 0\n",
    "\n",
    "    for batch_data in train_loader:\n",
    "        inputs, label = batch_data[0].to(device), batch_data[1].to(device);\n",
    "        \n",
    "        # Update Gradient\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            # Evaluate Model\n",
    "            output = model(inputs); \n",
    "            epoch_prob = torch.sigmoid(output); \n",
    "            loss = loss_fx(output, label.float()) * (1 - train_label_freq[label.cpu()[1]]); # Scale loss by the freq of NOT this class \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        # Accuracy\n",
    "        acc = (epoch_prob.argmax(dim=1) == label.argmax(dim=1)).float().mean(); \n",
    "        epoch_accuracy += acc / len(train_loader); \n",
    "        epoch_acc_values.append(acc)\n",
    "        \n",
    "        # Loss\n",
    "        epoch_loss += loss / len(train_loader);\n",
    "        epoch_loss_values.append(epoch_loss)\n",
    "#         print(f\"train loss: {loss.item():.4f}\")\n",
    "        wb.log({'T1-train_loss': loss, 'T1-train_acc': acc})\n",
    "\n",
    "    if epoch % val_interval == 0: # Validation Interval\n",
    "        with eval_mode(model):\n",
    "            epoch_val_accuracy = 0; epoch_val_loss = 0;\n",
    "            for val_data in val_loader:\n",
    "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "\n",
    "                val_output = model(val_images); val_prob = torch.sigmoid(val_output);\n",
    "                val_loss = loss_fx(val_output, val_labels.float())\n",
    "\n",
    "                val_acc = (val_prob.argmax(dim=1) == val_labels.argmax(dim=1)).float().mean()\n",
    "                epoch_val_accuracy += val_acc / len(val_loader)\n",
    "                epoch_val_loss += val_loss / len(val_loader)\n",
    "                wb.log({'T1-val_loss': val_loss, 'T1-val_acc': val_acc})\n",
    "        print(\n",
    "            f\"Epoch : {epoch+1} - train_loss : {epoch_loss:.4f} - train_acc: {epoch_accuracy:.4f} - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\"\n",
    "        )\n",
    "        \n",
    "        # Save Best Model\n",
    "        if best_valid_score > epoch_val_loss and epoch != 0:\n",
    "            print(f\"model saved to: {sp}-{run_id}.pth\")\n",
    "            save_model(epoch, sp, run_id)\n",
    "            best_valid_score = epoch_val_loss\n",
    "            \n",
    "    else:    \n",
    "        print(\n",
    "            f\"Epoch : {epoch+1} - train_loss : {epoch_loss:.4f} - train_acc: {epoch_accuracy:.4f} \\n\"\n",
    "        )\n",
    "modelfiles[0] = f\"{sp}-{run_id}.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94687ab-9f65-4394-8412-b1267b9213fa",
   "metadata": {},
   "source": [
    "# Train CNN for Functional Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443de70a-8790-4c3d-b450-e032d3e2ed0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms\n",
    "train_transforms = Compose([\n",
    "    AsChannelFirst(channel_dim=2),\n",
    "    Resize((512,512)),\n",
    "    EnsureType(data_type='tensor')]);\n",
    "train_ds = ImageDataset(image_files=fc[train_list], labels=train_lab, transform=train_transforms, reader='PILReader');\n",
    "\n",
    "val_transforms = Compose([\n",
    "    AsChannelFirst(channel_dim=2),\n",
    "    Resize((512,512)),\n",
    "    EnsureType(data_type='tensor')]);\n",
    "val_ds = ImageDataset(image_files=fc[valid_list], labels=valid_lab, transform=val_transforms, reader='PILReader');\n",
    "        \n",
    "# Define nifti dataset, data loader\n",
    "check_ds = ImageDataset(image_files=fc, labels=labels, transform=train_transforms);\n",
    "check_loader = DataLoader(check_ds, batch_size=1, num_workers=num_cores, pin_memory=pin_memory);\n",
    "\n",
    "im, label = monai.utils.misc.first(check_loader); print(im.shape, label, label.shape)\n",
    "plt.imshow(im[0,0,:,:].T, cmap=\"gray\", origin=\"lower\"); plt.axis('off'); del check_ds, check_loader, im, label;\n",
    "\n",
    "# create a training data loader\n",
    "train_ds = ImageDataset(image_files=fc[train_list], labels=train_lab, transform=train_transforms);\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_cores, pin_memory=pin_memory);\n",
    "\n",
    "# create a validation data loader\n",
    "val_ds = ImageDataset(image_files=fc[valid_list], labels=valid_lab, transform=val_transforms);\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, num_workers=num_cores, pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cca236-0a94-4a91-b826-90c95a521426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start a typical PyTorch training\n",
    "epoch_loss_values = [] # Pre-Allocate\n",
    "epoch_acc_values = [] # Pre-Allocate\n",
    "sp = os.path.join(rootDir,\"EPI\"); # Save Path\n",
    "\n",
    "# Create DenseNet264, CrossEntropyLoss and Adam optimizer\n",
    "model = monai.networks.nets.DenseNet264(spatial_dims=2, in_channels=3, out_channels=2,growth_rate=gr).to(device)\n",
    "# model.summary()\n",
    "wb.watch(model, log='all')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd) # Adam\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "best_valid_score = 99999; # Initialize Loss\n",
    "lastmodel = None\n",
    "for epoch in range(max_epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "\n",
    "    for batch_data in train_loader:\n",
    "        inputs, label = batch_data[0].to(device), batch_data[1].to(device);\n",
    "        \n",
    "        # Evaluate Model\n",
    "        output = model(inputs);\n",
    "        loss = loss_fx(output, label.float())\n",
    "        \n",
    "        # Update Gradient\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            # Evaluate Model\n",
    "            output = model(inputs); epoch_prob = torch.sigmoid(output)\n",
    "            loss = loss_fx(output, label.float()) * (1 - train_label_freq[label[1]]) # Scale loss by the freq of NOT this class\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        # Accuracy\n",
    "        acc = (epoch_prob.argmax(dim=1) == label.argmax(dim=1)).float().mean()\n",
    "        epoch_accuracy += acc / len(train_loader)\n",
    "        epoch_acc_values.append(acc)\n",
    "        \n",
    "        # Loss\n",
    "        epoch_loss += loss / len(train_loader)\n",
    "        epoch_loss_values.append(epoch_loss)\n",
    "#         print(f\"train loss: {loss.item():.4f}\")\n",
    "        wb.log({'EPI-train_loss': loss, 'EPI-train_acc': acc})\n",
    "\n",
    "    if epoch % val_interval == 0: # Validation Interval\n",
    "        with eval_mode(model):\n",
    "            epoch_val_accuracy = 0; epoch_val_loss = 0;\n",
    "            for val_data in val_loader:\n",
    "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "\n",
    "                val_output = model(val_images); val_prob = torch.sigmoid(val_output);\n",
    "                val_loss = loss_fx(val_output, val_labels.float())\n",
    "\n",
    "                val_acc = (val_prob.argmax(dim=1) == val_labels.argmax(dim=1)).float().mean()\n",
    "                epoch_val_accuracy += val_acc / len(val_loader)\n",
    "                epoch_val_loss += val_loss / len(val_loader)\n",
    "                wb.log({'EPI-val_loss': val_loss, 'EPI-val_acc': val_acc})\n",
    "        print(\n",
    "            f\"Epoch : {epoch+1} - train_loss : {epoch_loss:.4f} - train_acc: {epoch_accuracy:.4f} - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\"\n",
    "        )\n",
    "        \n",
    "        # Save Best Model\n",
    "        if best_valid_score > epoch_val_loss and epoch != 0:\n",
    "            print(f\"model saved to: {sp}-{run_id}.pth\")\n",
    "            save_model(epoch, sp, run_id)\n",
    "            best_valid_score = epoch_val_loss\n",
    "            \n",
    "    else:    \n",
    "        print(\n",
    "            f\"Epoch : {epoch+1} - train_loss : {epoch_loss:.4f} - train_acc: {epoch_accuracy:.4f} \\n\"\n",
    "        )\n",
    "wb.run.log_code(root=os.path.join(os.getcwd(),\"CNN_III.ipynb\")); \n",
    "modelfiles[1] = f\"{sp}-{run_id}.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5ca1c7-aee8-4dce-b67b-a02e52e800c7",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3405bff2-f041-4cfd-9dfd-ae72cae9900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(modelfile, df, mri_type):\n",
    "    print(\"Predict:\", modelfile, mri_type)  \n",
    "    # create a testing data loader\n",
    "    if mri_type == \"T1\":\n",
    "        val_transforms = Compose([\n",
    "            AddChannel(),\n",
    "            Spacing(\n",
    "                pixdim=(1.0, 1.0, 1.0), \n",
    "                mode=\"bilinear\", \n",
    "                image_only=True,\n",
    "            ),\n",
    "            Orientation(\n",
    "                axcodes=\"RAS\", \n",
    "                image_only=True,\n",
    "            ),\n",
    "            ScaleIntensity(\n",
    "                minv=0.0, \n",
    "                maxv=1.0, \n",
    "            ),\n",
    "            Resize(im_size),\n",
    "            EnsureType(data_type='tensor'),\n",
    "        ]);\n",
    "        test_ds = ImageDataset(image_files=images[df[\"id\"]], labels=test_lab, transform=val_transforms)\n",
    "        model = monai.networks.nets.DenseNet264(spatial_dims=3, in_channels=1, out_channels=2,growth_rate=gr).to(device)\n",
    "    elif mri_type == \"EPI\":\n",
    "        val_transforms = Compose([\n",
    "            AsChannelFirst(channel_dim=2),\n",
    "            Resize((512,512)),\n",
    "            EnsureType(data_type='tensor')]);\n",
    "        test_ds = ImageDataset(image_files=fc[df[\"id\"]], labels=test_lab, transform=val_transforms)\n",
    "        model = monai.networks.nets.DenseNet264(spatial_dims=2, in_channels=3, out_channels=2,growth_rate=gr).to(device)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, num_workers=num_cores, pin_memory=pin_memory)\n",
    "    checkpoint = torch.load(modelfile)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.eval()\n",
    "    \n",
    "    # Pre-allocate\n",
    "    y_pred = []\n",
    "    y_prob = []\n",
    "    \n",
    "    # Test Loop\n",
    "    for e, batch in enumerate(test_loader,1):\n",
    "        data = batch[0].to(device)\n",
    "        print(f\"{e}/{len(test_loader)}\", end=\"\\r\")\n",
    "        with torch.no_grad():\n",
    "            output = model(data);\n",
    "            tmp_prob = torch.sigmoid(output);\n",
    "            tmp_pred = tmp_prob.argmax(dim=1);\n",
    "            if (tmp_prob.size == 1):\n",
    "                y_pred.append(tmp_pred)\n",
    "                y_prob.append(tmp_prob)\n",
    "            else:\n",
    "                y_pred.extend(tmp_pred.tolist())\n",
    "                y_prob.extend(tmp_prob.tolist())\n",
    "    y_prob = [item[1] for item in y_prob] # Convert from One-Hot to Label Encoding\n",
    "    preddf = pd.DataFrame({\"id\": df[\"id\"], \"prob\": y_prob, \"pred\": y_pred}) \n",
    "    preddf = preddf.set_index(\"id\")\n",
    "    return preddf\n",
    "\n",
    "rep = 0\n",
    "mri_types = [\"T1\",\"EPI\"]\n",
    "df_pred = {\"id\": test_list, \"label\": test_label, \"prob\": 0, \"pred\": 0};\n",
    "for m, mtype in zip(modelfiles,  mri_types):\n",
    "    pred = predict(m, df_pred, mtype);\n",
    "    df_pred[\"prob\"] += pred[\"prob\"];\n",
    "df_pred[\"prob\"] /= len(modelfiles)\n",
    "df_pred[\"pred\"] = (df_pred[\"prob\"]>=0.5)+0\n",
    "\n",
    "acc = np.mean(((df_pred[\"prob\"]>=0.5) == df_pred[\"label\"]))\n",
    "auc = roc_auc_score(df_pred[\"label\"], df_pred[\"prob\"])\n",
    "\n",
    "# Confusion Matrix                             \n",
    "print(classification_report(\n",
    "    df_pred[\"label\"],\n",
    "    df_pred[\"pred\"],\n",
    "    target_names=[d.name for d in Diagnosis]))\n",
    "\n",
    "cm = confusion_matrix(\n",
    "    df_pred[\"label\"],\n",
    "    df_pred[\"pred\"],\n",
    "    normalize='true')\n",
    "\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=[d.name for d in Diagnosis])\n",
    "disp.plot(ax=plt.subplots(1, 1, facecolor='white')[1]);\n",
    "                            \n",
    "# Print and Log Overall Test Performance\n",
    "print(f\"Ensemble Test AUC: {auc:.4f} - Test ACC: {acc:.4f}\")\n",
    "wb.log({'test_acc': acc, 'test_auc': auc})\n",
    "rep += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62af5665-e36f-4a28-8a57-722c31a90ae9",
   "metadata": {},
   "source": [
    "# Occulusion Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9c1e16-bda4-44b8-86a6-bd3b12459ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cam = monai.visualize.CAM(nn_module=model_3d, target_layers=\"class_layers.relu\", fc_layers=\"class_layers.out\")\n",
    "cam = monai.visualize.GradCAMpp(\n",
    "    nn_module=model, target_layers=\"class_layers.relu\"\n",
    ")\n",
    "# cam = monai.visualize.GradCAMpp(nn_module=model_3d, target_layers=\"class_layers.relu\")\n",
    "print(\n",
    "    \"original feature shape\",\n",
    "    cam.feature_map_size([1, 1] + list(im_size), device),\n",
    ")\n",
    "print(\"upsampled feature shape\", [1, 1] + list(im_size))\n",
    "\n",
    "occ_sens = monai.visualize.OcclusionSensitivity(\n",
    "    nn_module=model, mask_size=12, n_batch=1, stride=24\n",
    ")\n",
    "\n",
    "# For occlusion sensitivity, inference must be run many times. Hence, we can use a\n",
    "# bounding box to limit it to a 2D plane of interest (z=the_slice) where each of\n",
    "# the arguments are the min and max for each of the dimensions (in this case CHWD).\n",
    "the_slice = train_ds[0][0].shape[-1] // 2\n",
    "occ_sens_b_box = [-1, -1, -1, -1, -1, -1, the_slice, the_slice]; print(occ_sens_b_box)\n",
    "\n",
    "train_transforms.set_random_state(42)\n",
    "n_examples = 3\n",
    "subplot_shape = [3, n_examples]\n",
    "fig, axes = plt.subplots(*subplot_shape, figsize=(25, 15), facecolor=\"white\")\n",
    "items = np.random.choice(len(train_ds), size=len(train_ds), replace=False)\n",
    "\n",
    "example = 0\n",
    "for item in items:\n",
    "\n",
    "    data = train_ds[\n",
    "        item\n",
    "    ]  # this fetches training data with random augmentations\n",
    "    image, label = data[0].to(device).unsqueeze(0), data[1][1]\n",
    "    y_pred = model(image); prob = torch.nn.functional.softmax(y_pred,dim=1);\n",
    "    pred_label = prob.argmax(dim=1);\n",
    "    \n",
    "    # Only display preMCI\n",
    "    if np.not_equal(label,1):\n",
    "        continue\n",
    "\n",
    "    img = image.detach().cpu().numpy()[..., the_slice]\n",
    "\n",
    "    name = \"actual: \"\n",
    "    name += \"preMCI\" if np.equal(label,1) else \"healthy\"\n",
    "    name += \"\\npred: \"\n",
    "    name += \"preMCI\" if np.equal(pred_label.cpu().numpy(),1) else \"healthy\"\n",
    "    name += f\"\\npreMCI: {prob[0,1]:.3}\"\n",
    "    name += f\"\\nhealthy: {prob[0,0]:.3}\"\n",
    "\n",
    "    # run CAM\n",
    "    cam_result = cam(x=image, class_idx=None)\n",
    "    cam_result = cam_result[..., the_slice]\n",
    "\n",
    "    # run occlusion\n",
    "    occ_result, _ = occ_sens(x=image, b_box=occ_sens_b_box)\n",
    "    occ_result = occ_result[..., pred_label];\n",
    "\n",
    "    for row, (im, title) in enumerate(\n",
    "        zip(\n",
    "            [img, cam_result, occ_result],\n",
    "            [name, \"CAM\", \"Occ. Sens.\"],\n",
    "        )\n",
    "    ):\n",
    "        cmap = \"gray\" if np.equal(row,0) else \"jet\"\n",
    "        ax = axes[row, example]\n",
    "        if isinstance(im, torch.Tensor):\n",
    "            im = im.cpu().detach()\n",
    "        \n",
    "        im_show = ax.imshow(np.squeeze(im[0][0].T), cmap=cmap, origin='lower')\n",
    "\n",
    "        ax.set_title(title, fontsize=25)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    example += 1\n",
    "    if example == n_examples:\n",
    "        break\n",
    "wb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2050206d-bcb0-4b15-ab86-1aa5f8e42122",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NGC-PyTorch-1.9",
   "language": "python",
   "name": "ngc-pytorch-1.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
